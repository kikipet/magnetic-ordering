{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'e3nn.point'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f56e212c1f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0me3nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataPeriodicNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatproj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPRester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagnetism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmendeleev\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'e3nn.point'"
     ]
    }
   ],
   "source": [
    "from e3nn.point.data_helpers import DataPeriodicNeighbors\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import pymatgen.analysis.magnetism.analyzer as pg\n",
    "import numpy as np\n",
    "from mendeleev import element\n",
    "import time, pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(filename):\n",
    "    return pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "def save_obj(obj, filename):\n",
    "    pickle.dump(obj, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31739/31739 [05:18<00:00, 99.78it/s] \n"
     ]
    }
   ],
   "source": [
    "order_list_mp = []\n",
    "structures_list_mp = []\n",
    "formula_list_mp = []\n",
    "sites_list = []\n",
    "id_list_mp = []\n",
    "y_values_mp = []\n",
    "order_encode = {\"NM\": 0, \"AFM\": 1, \"FM\": 2, \"FiM\": 2}\n",
    "\n",
    "magnetic_atoms = ['Ga', 'Tm', 'Y', 'Dy', 'Nb', 'Pu', 'Th', 'Er', 'U',\n",
    "                  'Cr', 'Sc', 'Pr', 'Re', 'Ni', 'Np', 'Nd', 'Yb', 'Ce',\n",
    "                  'Ti', 'Mo', 'Cu', 'Fe', 'Sm', 'Gd', 'V', 'Co', 'Eu',\n",
    "                  'Ho', 'Mn', 'Os', 'Tb', 'Ir', 'Pt', 'Rh', 'Ru']\n",
    "\n",
    "# m = MPRester(api_key='PqU1TATsbzHEOkSX', endpoint=None, notify_db_version=True, include_user_agent=True)\n",
    "m = MPRester(endpoint=None, include_user_agent=True)\n",
    "# get structures containing magnetic atoms\n",
    "structures = m.query(criteria={\"elements\": {\"$in\": magnetic_atoms}, 'blessed_tasks.GGA+U Static': {\n",
    "                     '$exists': True}}, properties=[\"material_id\", \"pretty_formula\", \"structure\", \"blessed_tasks\", \"nsites\"])\n",
    "\n",
    "structures_copy = structures.copy()\n",
    "for struc in structures_copy:\n",
    "    if len(struc[\"structure\"]) > 250:\n",
    "        structures.remove(struc)\n",
    "        print(\"MP Structure Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list = []\n",
    "for i in range(len(structures)):\n",
    "    order = pg.CollinearMagneticStructureAnalyzer(structures[i][\"structure\"])\n",
    "    order_list.append(order.ordering.name)  # i.e. FM, AM, NM\n",
    "id_NM = []\n",
    "id_FM = []\n",
    "id_AFM = []\n",
    "for i in range(len(structures)):\n",
    "    if order_list[i] == 'NM':\n",
    "        id_NM.append(i)\n",
    "    if order_list[i] == 'AFM':\n",
    "        id_AFM.append(i)\n",
    "    if order_list[i] == 'FM' or order_list[i] == 'FiM':\n",
    "        id_FM.append(i)\n",
    "np.random.shuffle(id_FM)\n",
    "np.random.shuffle(id_NM)\n",
    "np.random.shuffle(id_AFM)\n",
    "id_AFM, id_AFM_to_delete = np.split(id_AFM, [int(len(id_AFM))])\n",
    "id_NM, id_NM_to_delete = np.split(id_NM, [int(1.2*len(id_AFM))])\n",
    "id_FM, id_FM_to_delete = np.split(id_FM, [int(1.2*len(id_AFM))])\n",
    "\n",
    "structures_mp = [structures[i] for i in id_NM] + [structures[j]\n",
    "                                                  for j in id_FM] + [structures[k] for k in id_AFM]\n",
    "np.random.shuffle(structures_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding feature vector:  64 \n",
      "Number of channels per irreducible representation:  32 \n",
      "Number of tensor field convolution layers:   2 \n",
      "Maximum radius: 5.0 \n",
      "Number of basis:  10 \n",
      "AdamW optimizer learning rate: 0.0050 \n",
      "AdamW optimizer weight decay coefficient: 0.0300\n"
     ]
    }
   ],
   "source": [
    "for structure in structures_mp:\n",
    "    analyzed_structure = pg.CollinearMagneticStructureAnalyzer(\n",
    "        structure[\"structure\"])\n",
    "    order_list_mp.append(analyzed_structure.ordering)\n",
    "    structures_list_mp.append(structure[\"structure\"])\n",
    "    formula_list_mp.append(structure[\"pretty_formula\"])\n",
    "    id_list_mp.append(structure[\"material_id\"])\n",
    "    sites_list.append(structure[\"nsites\"])\n",
    "\n",
    "for order in order_list_mp:\n",
    "    y_values_mp.append(order_encode[order.name])\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'len_embed_feat': 64,\n",
    "          'num_channel_irrep': 32,\n",
    "          'num_e3nn_layer': 2,\n",
    "          'max_radius': 5,\n",
    "          'num_basis': 10,\n",
    "          'adamw_lr': 0.005,\n",
    "          'adamw_wd': 0.03\n",
    "          }\n",
    "\n",
    "# Used for debugging\n",
    "identification_tag = \"1:1:1.1 Relu wd:0.03 4 Linear\"\n",
    "cost_multiplier = 1.0\n",
    "\n",
    "print('Length of embedding feature vector: {:3d} \\n'.format(params.get('len_embed_feat')) +\n",
    "      'Number of channels per irreducible representation: {:3d} \\n'.format(params.get('num_channel_irrep')) +\n",
    "      'Number of tensor field convolution layers: {:3d} \\n'.format(params.get('num_e3nn_layer')) +\n",
    "      'Maximum radius: {:3.1f} \\n'.format(params.get('max_radius')) +\n",
    "      'Number of basis: {:3d} \\n'.format(params.get('num_basis')) +\n",
    "      'AdamW optimizer learning rate: {:.4f} \\n'.format(params.get('adamw_lr')) +\n",
    "      'AdamW optimizer weight decay coefficient: {:.4f}'.format(\n",
    "          params.get('adamw_wd'))\n",
    "      )\n",
    "\n",
    "\n",
    "run_name = (time.strftime(\"%y%m%d-%H%M\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct atomic species  82\n"
     ]
    }
   ],
   "source": [
    "structures = structures_list_mp\n",
    "y_values = y_values_mp\n",
    "id_list = id_list_mp\n",
    "\n",
    "\n",
    "species = set()\n",
    "count = 0\n",
    "for struct in structures[:]:\n",
    "    try:\n",
    "        species = species.union(list(set(map(str, struct.species))))\n",
    "        count += 1\n",
    "    except:\n",
    "        print(count)\n",
    "        count += 1\n",
    "        continue\n",
    "species = sorted(list(species))\n",
    "print(\"Distinct atomic species \", len(species))\n",
    "\n",
    "len_element = 118\n",
    "atom_types_dim = 3*len_element\n",
    "embedding_dim = params['len_embed_feat']\n",
    "lmax = 1\n",
    "# Roughly the average number (over entire dataset) of nearest neighbors for a given atom\n",
    "n_norm = 35\n",
    "\n",
    "Rs_in = [(45, 0, 1)]  # num_atom_types scalars (L=0) with even parity\n",
    "Rs_out = [(3, 0, 1)]  # len_dos scalars (L=0) with even parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 11 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 53 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 109 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 138 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 157 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 177 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 260 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 269 can't assign a NoneType to a torch.DoubleTensor\n",
      "Error: 334 can't assign a NoneType to a torch.DoubleTensor\n",
      "Encoding sample   497/ 6531\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 739, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 988, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 669, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n",
      "Exception closing connection <sqlite3.Connection object at 0x7f04573a45d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 739, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 988, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 669, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 247, in _close_connection\n",
      "    self._dialect.do_close(connection)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 675, in do_close\n",
      "    dbapi_connection.close()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sample   559/ 6531\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 739, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 988, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 669, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n",
      "Exception closing connection <sqlite3.Connection object at 0x7f044e276e40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 739, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 988, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 669, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 247, in _close_connection\n",
      "    self._dialect.do_close(connection)\n",
      "  File \"/home/skim52/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 675, in do_close\n",
      "    dbapi_connection.close()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139663055468352 and this is thread id 139658129565440.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sample   586/ 6531\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3364b1bdaf21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             input[j, int(element(str(site.specie)).atomic_number)\n\u001b[0;32m---> 11\u001b[0;31m                   ] = element(str(site.specie)).atomic_radius\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;31m#input[j, len_element + int(element(str(site.specie)).atomic_number) +1] = element(str(site.specie)).atomic_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             input[j, len_element + int(element(str(site.specie)).atomic_number) +\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/mendeleev/mendeleev.py\u001b[0m in \u001b[0;36melement\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/mendeleev/mendeleev.py\u001b[0m in \u001b[0;36m_get_element\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"tin\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m         \"\"\"\n\u001b[0;32m-> 2856\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0mstatement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_statement_20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2894\u001b[0;31m         result = self.session.execute(\n\u001b[0m\u001b[1;32m   2895\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, **kw)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompile_state_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             result = compile_state_cls.orm_setup_cursor_result(\n\u001b[0m\u001b[1;32m   1693\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/context.py\u001b[0m in \u001b[0;36morm_setup_cursor_result\u001b[0;34m(cls, session, statement, params, execution_options, bind_arguments, result)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mbind_arguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerycontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/loading.py\u001b[0m in \u001b[0;36minstances\u001b[0;34m(cursor, context)\u001b[0m\n\u001b[1;32m     67\u001b[0m         (process, labels, extra) = list(\n\u001b[1;32m     68\u001b[0m             zip(\n\u001b[0;32m---> 69\u001b[0;31m                 *[\n\u001b[0m\u001b[1;32m     70\u001b[0m                     \u001b[0mquery_entity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mquery_entity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/loading.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m             zip(\n\u001b[1;32m     69\u001b[0m                 *[\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mquery_entity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mquery_entity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 ]\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/context.py\u001b[0m in \u001b[0;36mrow_processor\u001b[0;34m(self, context, result)\u001b[0m\n\u001b[1;32m   2514\u001b[0m             \u001b[0monly_load_props\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefresh_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2516\u001b[0;31m         _instance = loading._instance_processor(\n\u001b[0m\u001b[1;32m   2517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/loading.py\u001b[0m in \u001b[0;36m_instance_processor\u001b[0;34m(query_entity, mapper, context, result, path, adapter, only_load_props, refresh_state, polymorphic_discriminator, _polymorphic_from)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0mpopulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcached_populators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"todo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         prop.create_row_processor(\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_entity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/interfaces.py\u001b[0m in \u001b[0;36mcreate_row_processor\u001b[0;34m(self, context, query_entity, path, mapper, result, adapter, populators)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mstrat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         strat.create_row_processor(\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mquery_entity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py\u001b[0m in \u001b[0;36mcreate_row_processor\u001b[0;34m(self, context, query_entity, path, loadopt, mapper, result, adapter, populators)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         subq = self._setup_query_from_rowproc(\n\u001b[0m\u001b[1;32m   1822\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m             \u001b[0mquery_entity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py\u001b[0m in \u001b[0;36m_setup_query_from_rowproc\u001b[0;34m(self, context, query_entity, path, entity, loadopt, adapter)\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0;31m# much of this we need.    in particular I can't get a test to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0;31m# fail if the \"set_base_alias\" is missing and not sure why that is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m         orig_compile_state = compile_state_cls._create_entities_collection(\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0morig_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/context.py\u001b[0m in \u001b[0;36m_create_entities_collection\u001b[0;34m(cls, query, legacy)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;31m# entities will also set up polymorphic adapters for mappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;31m# that have with_polymorphic configured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         _QueryEntity.to_compile_state(\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_current_entities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_old/lib/python3.8/site-packages/sqlalchemy/orm/context.py\u001b[0m in \u001b[0;36mto_compile_state\u001b[0;34m(cls, compile_state, entities, entities_collection, is_current_entities)\u001b[0m\n\u001b[1;32m   2371\u001b[0m                         )\n\u001b[1;32m   2372\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2373\u001b[0;31m                         _ColumnEntity._for_columns(\n\u001b[0m\u001b[1;32m   2374\u001b[0m                             \u001b[0mcompile_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m                         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "count = 0\n",
    "indices_to_delete = []\n",
    "for i, struct in enumerate(structures):\n",
    "    try:\n",
    "        print(\n",
    "            f\"Encoding sample {i+1:5d}/{len(structures):5d}\", end=\"\\r\", flush=True)\n",
    "        input = torch.zeros(len(struct), 3*len_element)\n",
    "        for j, site in enumerate(struct):\n",
    "            input[j, int(element(str(site.specie)).atomic_number)\n",
    "                  ] = element(str(site.specie)).atomic_radius\n",
    "            #input[j, len_element + int(element(str(site.specie)).atomic_number) +1] = element(str(site.specie)).atomic_weight\n",
    "            input[j, len_element + int(element(str(site.specie)).atomic_number) +\n",
    "                  1] = element(str(site.specie)).en_pauling  # error?\n",
    "            input[j, 2*len_element + int(element(str(site.specie)).atomic_number) + 1] = element(\n",
    "                str(site.specie)).dipole_polarizability\n",
    "        data.append(DataPeriodicNeighbors(\n",
    "            x=input, Rs_in=None,\n",
    "            pos=torch.tensor(struct.cart_coords.copy()), lattice=torch.tensor(struct.lattice.matrix.copy()),\n",
    "            r_max=params['max_radius'],\n",
    "            y=(torch.tensor([y_values[i]])).to(torch.long),\n",
    "            n_norm=n_norm,\n",
    "        ))\n",
    "\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        indices_to_delete.append(i)\n",
    "        print(f\"Error: {count} {e}\", end=\"\\n\")\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "struc_dictionary = dict()\n",
    "for i in range(len(structures)):\n",
    "    struc_dictionary[i] = structures[i]\n",
    "\n",
    "id_dictionary = dict()\n",
    "for i in range(len(id_list)):\n",
    "    id_dictionary[i] = id_list[i]\n",
    "\n",
    "for i in indices_to_delete:\n",
    "    del struc_dictionary[i]\n",
    "    del id_dictionary[i]\n",
    "\n",
    "structures2 = []\n",
    "for i in range(len(structures)):\n",
    "    if i in struc_dictionary.keys():\n",
    "        structures2.append(struc_dictionary[i])\n",
    "structures = structures2\n",
    "\n",
    "id2 = []\n",
    "for i in range(len(id_list)):\n",
    "    if i in id_dictionary.keys():\n",
    "        id2.append(id_dictionary[i])\n",
    "id_list = id2\n",
    "\n",
    "compound_list = []\n",
    "for i, struc in enumerate(structures):\n",
    "    str_struc = (str(struc))\n",
    "    count = 0\n",
    "    while str_struc[count] != \":\":\n",
    "        count += 1\n",
    "    str_struc = str_struc[count+2:]\n",
    "    count = 0\n",
    "    while str_struc[count:count+3] != \"abc\":\n",
    "        count += 1\n",
    "    str_struc = str_struc[:count]\n",
    "    compound_list.append(str_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, run_name+'_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9540b84e393498cb50b584a75dda43201c9f3d00c7841c7191755d6e197bf401"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
