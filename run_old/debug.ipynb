{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "\n",
    "import e3nn\n",
    "from e3nn import rs, o3\n",
    "from e3nn.point.data_helpers import DataPeriodicNeighbors\n",
    "from e3nn.networks import GatedConvParityNetwork\n",
    "from e3nn.kernel_mod import Kernel\n",
    "from e3nn.point.message_passing import Convolution\n",
    "\n",
    "import pymatgen as mg\n",
    "import pymatgen.io\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import pymatgen.analysis.magnetism.analyzer as pg\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mendeleev import element\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import io\n",
    "import random\n",
    "import math\n",
    "import sys \n",
    "import time, os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding feature vector:  64 \n",
      "Number of channels per irreducible representation:  32 \n",
      "Number of tensor field convolution layers:   2 \n",
      "Maximum radius: 5.0 \n",
      "Number of basis:  10 \n",
      "AdamW optimizer learning rate: 0.0050 \n",
      "AdamW optimizer weight decay coefficient: 0.0300\n",
      "{'convolution': <class 'e3nn.point.message_passing.Convolution'>, 'kernel': <class 'e3nn.kernel_mod.Kernel'>, 'Rs_in': [(45, 0, 1)], 'Rs_out': [(3, 0, 1)], 'mul': 32, 'layers': 2, 'max_radius': 5, 'lmax': 1, 'number_of_basis': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51877/307961657.py:85: DeprecationWarning: Call to deprecated function GatedConvParityNetwork.\n",
      "  model = AtomEmbeddingAndSumLastLayer(atom_types_dim, embedding_dim, GatedConvParityNetwork(**model_kwargs))\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'len_embed_feat': 64,\n",
    "          'num_channel_irrep': 32,\n",
    "          'num_e3nn_layer': 2,\n",
    "          'max_radius': 5,\n",
    "          'num_basis': 10,\n",
    "          'adamw_lr': 0.005,\n",
    "          'adamw_wd': 0.03\n",
    "         }\n",
    "\n",
    "#Used for debugging\n",
    "identification_tag = \"1:1:1.1 Relu wd:0.03 4 Linear\"\n",
    "cost_multiplier = 1.0\n",
    "\n",
    "print('Length of embedding feature vector: {:3d} \\n'.format(params.get('len_embed_feat')) + \n",
    "      'Number of channels per irreducible representation: {:3d} \\n'.format(params.get('num_channel_irrep')) +\n",
    "      'Number of tensor field convolution layers: {:3d} \\n'.format(params.get('num_e3nn_layer')) + \n",
    "      'Maximum radius: {:3.1f} \\n'.format(params.get('max_radius')) +\n",
    "      'Number of basis: {:3d} \\n'.format(params.get('num_basis')) +\n",
    "      'AdamW optimizer learning rate: {:.4f} \\n'.format(params.get('adamw_lr')) + \n",
    "      'AdamW optimizer weight decay coefficient: {:.4f}'.format(params.get('adamw_wd'))\n",
    "     )\n",
    "\n",
    "\n",
    "run_name = (time.strftime(\"%y%m%d-%H%M\", time.localtime()))\n",
    "\n",
    "\n",
    "\n",
    "len_element = 118\n",
    "atom_types_dim = 3*len_element\n",
    "embedding_dim = params['len_embed_feat']\n",
    "lmax = 1\n",
    "n_norm = 35  # Roughly the average number (over entire dataset) of nearest neighbors for a given atom\n",
    "\n",
    "Rs_in = [(45, 0, 1)]  # num_atom_types scalars (L=0) with even parity\n",
    "Rs_out = [(3,0,1)]  # len_dos scalars (L=0) with even parity\n",
    "\n",
    "model_kwargs = {\n",
    "    \"convolution\": Convolution,\n",
    "    \"kernel\": Kernel,\n",
    "    \"Rs_in\": Rs_in,\n",
    "    \"Rs_out\": Rs_out,\n",
    "    \"mul\": params['num_channel_irrep'], # number of channels per irrep (differeing L and parity)\n",
    "    \"layers\": params['num_e3nn_layer'],\n",
    "    \"max_radius\": params['max_radius'],\n",
    "    \"lmax\": lmax,\n",
    "    \"number_of_basis\": params['num_basis']\n",
    "}\n",
    "print(model_kwargs)\n",
    "        \n",
    "class AtomEmbeddingAndSumLastLayer(torch.nn.Module):\n",
    "    def __init__(self, atom_type_in, atom_type_out, model):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(atom_type_in, 128)\n",
    "        self.model = model\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(128, 96)\n",
    "        self.linear3 = torch.nn.Linear(96, 64)\n",
    "        self.linear4 = torch.nn.Linear(64, 45)\n",
    "        #self.linear5 = torch.nn.Linear(45, 32)\n",
    "        #self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x, *args, batch=None, **kwargs):\n",
    "        output = self.linear(x)\n",
    "        output = self.relu(output)\n",
    "        print(f\"Input: {x}\")\n",
    "        output = self.linear2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear3(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear4(output)\n",
    "        #output = self.linear5(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.model(output, *args, **kwargs)\n",
    "        if batch is None:\n",
    "            N = output.shape[0]\n",
    "            batch = output.new_ones(N)\n",
    "        output = torch_scatter.scatter_add(output, batch, dim=0)\n",
    "        print(f\"Output: {output}\")\n",
    "        #output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "model = AtomEmbeddingAndSumLastLayer(atom_types_dim, embedding_dim, GatedConvParityNetwork(**model_kwargs))\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=params['adamw_lr'], weight_decay=params['adamw_wd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomEmbeddingAndSumLastLayer(\n",
       "  (linear): Linear(in_features=354, out_features=128, bias=True)\n",
       "  (model): GatedConvParityNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Convolution()\n",
       "        (1): GatedBlockParity (32x0e + 32x0e + 32x1o -> 32x0e,32x1o)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): Convolution()\n",
       "        (1): GatedBlockParity (32x0e + 64x0e + 32x1e,32x1o -> 32x0e,32x1e,32x1o)\n",
       "      )\n",
       "      (2): Convolution()\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=128, out_features=96, bias=True)\n",
       "  (linear3): Linear(in_features=96, out_features=64, bias=True)\n",
       "  (linear4): Linear(in_features=64, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedConvParityNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Convolution()\n",
       "      (1): GatedBlockParity (32x0e + 32x0e + 32x1o -> 32x0e,32x1o)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Convolution()\n",
       "      (1): GatedBlockParity (32x0e + 64x0e + 32x1e,32x1o -> 32x0e,32x1e,32x1o)\n",
       "    )\n",
       "    (2): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9540b84e393498cb50b584a75dda43201c9f3d00c7841c7191755d6e197bf401"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('e3nn_old')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
