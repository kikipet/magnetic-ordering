{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from data_helpers import DataPeriodicNeighbors\n",
    "from e3nn.nn.models.gate_points_2101 import Convolution, Network\n",
    "from e3nn.o3 import Irreps\n",
    "\n",
    "import pymatgen as mg\n",
    "import pymatgen.io\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import pymatgen.analysis.magnetism.analyzer as pg\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mendeleev import element\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import io\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('magnetic_order_data.pt')\n",
    "id_list = []  # list of material ids\n",
    "\n",
    "run_name = (time.strftime(\"%y%m%d-%H%M\", time.localtime()))\n",
    "\n",
    "order_list_mp = []\n",
    "structures_list_mp = []\n",
    "formula_list_mp = []\n",
    "sites_list = []\n",
    "id_list_mp = []\n",
    "y_values_mp = []\n",
    "order_encode = {\"NM\": 0, \"AFM\": 1, \"FM\": 2, \"FiM\": 2}\n",
    "\n",
    "magnetic_atoms = ['Ga', 'Tm', 'Y', 'Dy', 'Nb', 'Pu', 'Th', 'Er', 'U',\n",
    "                  'Cr', 'Sc', 'Pr', 'Re', 'Ni', 'Np', 'Nd', 'Yb', 'Ce',\n",
    "                  'Ti', 'Mo', 'Cu', 'Fe', 'Sm', 'Gd', 'V', 'Co', 'Eu',\n",
    "                  'Ho', 'Mn', 'Os', 'Tb', 'Ir', 'Pt', 'Rh', 'Ru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'len_embed_feat': 64,\n",
    "          'num_channel_irrep': 32,\n",
    "          'num_e3nn_layer': 2,\n",
    "          'max_radius': 5,\n",
    "          'num_basis': 10,\n",
    "          'adamw_lr': 0.005,\n",
    "          'adamw_wd': 0.03,\n",
    "          'radial_layers': 3\n",
    "          }\n",
    "\n",
    "# Used for debugging\n",
    "identification_tag = \"1:1:1.1 Relu wd:0.03 4 Linear\"\n",
    "cost_multiplier = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_element = 118\n",
    "atom_types_dim = 3*len_element\n",
    "embedding_dim = params['len_embed_feat']\n",
    "lmax = 1\n",
    "# Roughly the average number (over entire dataset) of nearest neighbors for a given atom\n",
    "n_norm = 35\n",
    "\n",
    "# num_atom_types scalars (L=0) with even parity\n",
    "irreps_in = Irreps([(45, (0, 1))])\n",
    "irreps_hidden = Irreps([(64, (0, 1))])  # not sure\n",
    "irreps_out = Irreps([(3, (0, 1))])  # len_dos scalars (L=0) with even parity\n",
    "\n",
    "model_kwargs = {\n",
    "    \"irreps_in\": irreps_in,\n",
    "    \"irreps_hidden\": irreps_hidden,\n",
    "    \"irreps_out\": irreps_out,\n",
    "    \"irreps_node_attr\": '0e+1e',  # not really sure\n",
    "    \"irreps_edge_attr\": '0e+1e',  # not really sure\n",
    "    \"layers\": params['num_e3nn_layer'],\n",
    "    \"max_radius\": params['max_radius'],\n",
    "    \"number_of_basis\": params['num_basis'],\n",
    "    \"radial_layers\": params['radial_layers'],\n",
    "    # for these last 3 I don't know what's normal\n",
    "    \"radial_neurons\": 5,\n",
    "    \"num_neighbors\": 5,\n",
    "    \"num_nodes\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomEmbeddingAndSumLastLayer(torch.nn.Module):\n",
    "    def __init__(self, atom_type_in, atom_type_out, model):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(atom_type_in, 128)\n",
    "        self.model = model\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(128, 96)\n",
    "        self.linear3 = torch.nn.Linear(96, 64)\n",
    "        self.linear4 = torch.nn.Linear(64, 45)\n",
    "        #self.linear5 = torch.nn.Linear(45, 32)\n",
    "        #self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, *args, batch=None, **kwargs):\n",
    "        output = self.linear(x)\n",
    "        output = self.relu(output)\n",
    "        print(f\"Input: {x}\")\n",
    "        output = self.linear2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear3(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear4(output)\n",
    "        #output = self.linear5(output)\n",
    "        output = self.relu(output)\n",
    "        print(output)\n",
    "        output = self.model(output, *args, **kwargs)\n",
    "        if batch is None:\n",
    "            N = output.shape[0]\n",
    "            batch = output.new_ones(N)\n",
    "        output = torch_scatter.scatter_add(output, batch, dim=0)\n",
    "        print(f\"Output: {output}\")\n",
    "        #output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AtomEmbeddingAndSumLastLayer(\n",
    "    atom_types_dim, embedding_dim, Network(**model_kwargs))\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(), lr=params['adamw_lr'], weight_decay=params['adamw_wd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "index_tr, index_va, index_te = np.split(\n",
    "    indices, [int(.8 * len(indices)), int(.9 * len(indices))])\n",
    "\n",
    "assert set(index_tr).isdisjoint(set(index_te))\n",
    "assert set(index_tr).isdisjoint(set(index_va))\n",
    "assert set(index_te).isdisjoint(set(index_va))\n",
    "\n",
    "\n",
    "with open('loss.txt', 'a') as f:\n",
    "    f.write(f\"Iteration: {identification_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = torch_geometric.loader.DataLoader(\n",
    "    [data[i] for i in index_tr], batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = torch_geometric.loader.DataLoader(\n",
    "    [data[i] for i in index_va], batch_size=batch_size)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(self, data: Union[Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "#         \"\"\"evaluate the network\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         data : `torch_geometric.data.Data` or dict\n",
    "#             data object containing\n",
    "#             - ``pos`` the position of the nodes (atoms)\n",
    "#             - ``x`` the input features of the nodes, optional\n",
    "#             - ``z`` the attributes of the nodes, for instance the atom type, optional\n",
    "#             - ``batch`` the graph to which the node belong, optional\n",
    "#         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0.1477, 0.2837, 0.2596,  ..., 0.2000, 0.0595, 0.3252],\n",
      "        [0.1477, 0.2837, 0.2596,  ..., 0.2000, 0.0595, 0.3252],\n",
      "        [0.1477, 0.2837, 0.2596,  ..., 0.2000, 0.0595, 0.3252],\n",
      "        ...,\n",
      "        [0.2707, 0.0982, 0.2417,  ..., 0.0401, 0.0211, 0.1366],\n",
      "        [0.2707, 0.0982, 0.2417,  ..., 0.0401, 0.0211, 0.1366],\n",
      "        [0.2707, 0.0982, 0.2417,  ..., 0.0401, 0.0211, 0.1366]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6775/229727120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlen2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# output = model([[len1, len2], d.edge_index, d.edge_attr], batch=d.batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_new/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1112\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6775/1469564363.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_new/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1112\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_new/lib/python3.8/site-packages/e3nn/nn/models/gate_points_2101.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mbelong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'batch'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/e3nn_new/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;34m\"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."
     ]
    }
   ],
   "source": [
    "for j, d in enumerate(dataloader):\n",
    "    d.to(device)\n",
    "    len1 = len(d.x)\n",
    "    len2 = len(d.x[0]) if len1 > 0 else 0\n",
    "    output = model(d.x,  batch=d.batch)\n",
    "    # output = model([[len1, len2], d.edge_index, d.edge_attr], batch=d.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datapoint.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataPeriodicNeighborsBatch(edge_index=[2, 2844], edge_attr=[2844, 3], pos=[52, 3], x=[52, 354], y=[1], n_norm=[1], lattice=[3, 3], batch=[52], ptr=[2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a76aca0647ecd8dec4c3fdc40dacc2d3e474d7a7a3cb408df2817eb18c7a4f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('e3nn_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
