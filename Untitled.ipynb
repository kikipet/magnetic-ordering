{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae66655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import e3nn\n",
    "import e3nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc588ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_element = 118\n",
    "atom_types_dim = 3*len_element\n",
    "embedding_dim = params['len_embed_feat']\n",
    "lmax = 1\n",
    "n_norm = 35  # Roughly the average number (over entire dataset) of nearest neighbors for a given atom\n",
    "\n",
    "Rs_in = [(45, 0, 1)]  # num_atom_types scalars (L=0) with even parity\n",
    "Rs_out = [(3,0,1)]  # len_dos scalars (L=0) with even parity\n",
    "\n",
    "model_kwargs = {\n",
    "    \"convolution\": Convolution,\n",
    "    \"kernel\": Kernel,\n",
    "    \"Rs_in\": Rs_in,\n",
    "    \"Rs_out\": Rs_out,\n",
    "    \"mul\": params['num_channel_irrep'], # number of channels per irrep (differeing L and parity)\n",
    "    \"layers\": params['num_e3nn_layer'],\n",
    "    \"max_radius\": params['max_radius'],\n",
    "    \"lmax\": lmax,\n",
    "    \"number_of_basis\": params['num_basis']\n",
    "}\n",
    "print(model_kwargs)\n",
    "        \n",
    "class AtomEmbeddingAndSumLastLayer(torch.nn.Module):\n",
    "    def __init__(self, atom_type_in, atom_type_out, model):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(atom_type_in, 128)\n",
    "        self.model = model\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(128, 96)\n",
    "        self.linear3 = torch.nn.Linear(96, 64)\n",
    "        self.linear4 = torch.nn.Linear(64, 45)\n",
    "        #self.linear5 = torch.nn.Linear(45, 32)\n",
    "        #self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x, *args, batch=None, **kwargs):\n",
    "        output = self.linear(x)\n",
    "        output = self.relu(output)\n",
    "        print(f\"Input: {x}\")\n",
    "        output = self.linear2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear3(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear4(output)\n",
    "        #output = self.linear5(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.model(output, *args, **kwargs)\n",
    "        if batch is None:\n",
    "            N = output.shape[0]\n",
    "            batch = output.new_ones(N)\n",
    "        output = torch_scatter.scatter_add(output, batch, dim=0)\n",
    "        print(f\"Output: {output}\")\n",
    "        #output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "model = AtomEmbeddingAndSumLastLayer(atom_types_dim, embedding_dim, GatedConvParityNetwork(**model_kwargs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_base",
   "language": "python",
   "name": "conda_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
